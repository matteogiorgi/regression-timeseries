\documentclass[11pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{url}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{enumitem}
\usepackage{natbib}
\usepackage{inconsolata}
\usepackage{graphicx}



% -----------------------------------------------------
% Elegant R Code Style for Listings
% -----------------------------------------------------
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.97,0.97,0.97}
\definecolor{backcolour2}{rgb}{1.00,1.00,0.90}
% ---
\definecolor{rcodebg}{rgb}{1.00,1.00,0.95}
\definecolor{rkeyword}{rgb}{0.00,0.20,0.60}   % blu elegante
\definecolor{rcomment}{rgb}{0.00,0.45,0.00}   % verde leggibile
\definecolor{rstring}{rgb}{0.65,0.10,0.10}    % rosso caldo

\lstdefinestyle{rstyle}{
    language=R,
    backgroundcolor=\color{backcolour},
    basicstyle=\ttfamily\small,
    commentstyle=\itshape\color{rcomment},
    keywordstyle=\color{.},
    stringstyle=\color{rstring},
    numbers=none,
    showstringspaces=false,
    tabsize=4,
    breaklines=true,
    breakatwhitespace=true,
    captionpos=b,
    frame=single,
    rulecolor=\color{black!20},
    frameround=ffff
}

% -----------------------------------------------------
% Style for R console output (summary(model), etc.)
% -----------------------------------------------------
\lstdefinestyle{routput}{
    basicstyle=\ttfamily\footnotesize,
    backgroundcolor=\color{backcolour2},
    frame=single,
    rulecolor=\color{black!20},
    frameround=ffff,
    breaklines=true,
    breakatwhitespace=false,
    showstringspaces=false,
    numbers=none
}





\setlist[itemize]{topsep=2pt, itemsep=2pt, parsep=0pt, partopsep=0pt}

% Page layout
\geometry{margin=1in}
\onehalfspacing

% Hyperlink colors
\hypersetup{
    colorlinks=true,
    linkcolor=rstring,
    urlcolor=rkeyword,
    citecolor=rcomment
}

% Title page
\title{\textbf{Group10 AmesHousing}}
\author{
\begin{tabular}{c}
\textbf{Authors} \\
Mattia Zanin -- \href{mailto:mattia.zanin@studenti.unipd.it}{mattia.zanin@studenti.unipd.it} \\
Matteo Giorgi -- \href{mailto:matteo.giorgi.1@studenti.unipd.it}{matteo.giorgi.1@studenti.unipd.it} \\
Enrico Zanello -- \href{mailto:enrico.zanello@studenti.unipd.it}{enrico.zanello@studenti.unipd.it} \\
Luca Lo Buono -- \href{mailto:luca.lobuono@studenti.unipd.it}{luca.lobuono@studenti.unipd.it} \\
\end{tabular}
}
\date{November 23, 2025}

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\tableofcontents
\newpage

% ================================
% Introduction
% ================================
\section{Research hypotheses supported by the literature}

The objective of this work is to study which structural, qualitative, and locational characteristics of a residential property significantly affect its market price.

For the purpose of this assignment, we selected a subset of variables, listed in the \textit{Ames Housing Dataset}, most commonly used in real estate pricing models and supported by the existing literature.

% ----------------------------------------------------------
\subsection{Fundamental variables and assumptions}

Previous work shows that approximately 80\% of the variation in residential sale prices can be explained simply by considering the neighborhood and the total square footage of the dwelling (computed as \texttt{Total Bsmt SF} + \texttt{Gr Liv Area}) \cite{DeCock2011}.

According to our interpretation of the literature published by \cite{Han2023} and \cite{Zietz2008}, together with our empirical reasoning, we consider the following variables to have a significant impact on the sale price of a house.

% ----------------------------------------------------------
\subsubsection{Overall quality has a strong positive impact on sale price}

Several studies show that global quality assessments summarize multiple latent characteristics (such as materials, workmanship, and design), making them among the most informative predictors of house value.

\cite{Abdulhafedh2022} identifies \texttt{Overall Qual} as one of the most influential variables in explaining sale price in a multiple regression framework.

Similar evidence is reported in \cite{Han2023}, where overall quality consistently appears as the strongest determinant in both OLS and regularized regression models.

% ----------------------------------------------------------
\subsubsection{Above--ground living area (\texttt{Gr Liv Area}) is positively associated with sale price}

\cite{Abdulhafedh2022} highlights that the main livable area is among the variables with the highest explanatory power.
Studies on the Ames dataset by \cite{Ye2024} and \cite{Han2023} similarly identify \texttt{Gr Liv Area} as one of the strongest continuous predictors.

% ----------------------------------------------------------
\subsubsection{Total basement area (\texttt{Total Bsmt SF}) also increases sale price}

Basements provide additional functional space and generally correlate with larger, higher--value homes.

Multiple analyses of the Ames dataset \cite{Han2023} show that basement size remains statistically significant even when controlling for other structural variables.
\cite{Abdulhafedh2022} also finds that basement--related features contribute substantially to model fit.

% ----------------------------------------------------------
\subsubsection{Newer or recently renovated houses (\texttt{Year Built}, \texttt{Year Remod/Add}) tend to have higher prices}

The literature on housing depreciation demonstrates that structural aging reduces property value unless offset by renovations.

According to \cite{Abdulhafedh2022}, both the construction year and the remodeling year play an important role in predicting sale prices.

Other studies on the Ames dataset reinforce this conclusion, noting that newer homes or homes with extensive remodeling command a price premium.

% ----------------------------------------------------------
\subsubsection{Higher--quality kitchens and exterior materials positively influence sale price}

Studies in real--estate economics show that buyers are particularly sensitive to the quality of kitchens, bathrooms, and exterior finishes, as these elements influence both functionality and aesthetic appeal.

\texttt{Kitchen Qual} and \texttt{Exter Qual} are repeatedly found to be statistically significant predictors in analyses using the Ames dataset \cite{Ye2024, Abdulhafedh2022}.
Both variables capture qualitative assessments that are not reflected solely by house size.

% ----------------------------------------------------------
\subsubsection{Neighborhood characteristics significantly affect sale price}

Location remains one of the most important determinants of housing prices in real estate pricing models.

The Ames dataset includes a categorical variable (\texttt{Neighborhood}) that encodes proximity to schools, income areas, and local amenities.

Previous studies \cite{DeCock2011, Ye2024} demonstrate that location dummies remain significant even in fully specified regression models.


% ================================
% Literature Review
% ================================
\subsection{Variables we remove}

We begin by removing the variables \texttt{Pool QC}, \texttt{Alley}, \texttt{Fence}, and \texttt{Misc Feature}, since they contain a large proportion of missing observations (\texttt{NaN}).
Although the remaining variables would be available for analysis, including irrelevant or noisy predictors increases the standard errors of the estimated coefficients, leading to less powerful significance tests, wider confidence intervals, and ultimately less precise statistical inference.

For this reason, we exclude many of the 82 explanatory variables originally present in the dataset.
Several of them refer to the same structural component of the house (e.g., \texttt{Bsmt Exposure}, \texttt{BsmtFin Type 1}, \texttt{BsmtFin Type 2} all describe basement characteristics), potentially resulting in high collinearity and inflated standard errors.
Additionally, we believe that some features have only a negligible impact on sale prices. To obtain a more parsimonious model-—characterized by a higher adjusted $R^2$ and lower AIC and BIC, we decided not to include these variables in our analysis.

Examples of excluded variables include:

\begin{itemize}
    \item \texttt{PID}: an identification number that carries no information about the price
    \item \texttt{Lot Front}: the length of the street frontage. Its effect is ambiguous (a larger frontage might be positive, but may also imply more noise and traffic)
    \item \texttt{Lot Shape} and \texttt{Land Contour}: less relevant than broader locational attributes such as neighborhood
    \item \texttt{Fireplaces}: the number of fireplaces, an outdated feature with limited impact on modern housing prices
    \item \texttt{FireplaceQu}: fireplace quality, which is of secondary importance relative to other quality indicators (e.g., kitchen and exterior quality)
    \item \texttt{Roof Style} and \texttt{Roof Matl}: roofing attributes that are less relevant compared to major structural and quality variables
    \item \texttt{Condition 1}: proximity to conditions such as arterial roads or railways. Since \texttt{Neighborhood} captures location effects more comprehensively, including this variable may introduce redundancy, and noise may still distort its interpretation
\end{itemize}


% ================================
% Data Description
% ================================
\section{Description of the dataset}

The \textit{Ames Housing Dataset} provides detailed information on dwellings sold in Ames (Iowa) and is an updated version of the \textit{Boston Housing Dataset}, already widely used in the housing economics literature. With its 2930 observations, the Ames dataset offers a larger sample size and a more comprehensive set of features, making it better suited for modern statistical analysis.

% The dataset includes information regarding physical size, construction details, quality ratings, and neighborhood indicators.
It contains detailed information on residential properties sold between 2006 and 2010.
In its full version, the dataset includes 82 explanatory variables describing structural, qualitative, locational, and functional characteristics of each house.
Based on these variables, we formulate a set of hypotheses grounded in empirical findings from the real--estate and housing--econometrics literature.

This dataset is a well-known real--estate dataset originally compiled by the Assessor’s Office of Ames, Iowa.

% ---------------------------------------

\subsection{General structure of the dataset}

Each row of the dataset corresponds to a single residential property, while columns represent the attributes listed above.

The dependent variable of the regression is \texttt{SalePrice} (expressed in US dollars) and the selected explanatory variables fall into the three following categories.

% ---------------------------------------

\subsubsection{Size and structural characteristics}

These variables capture the physical dimensions and structural attributes of the dwelling:

\begin{itemize}
    \item \texttt{Gr Liv Area}: above--ground living area (square feet)
    \item \texttt{1st Flr SF}: first--floor area
    \item \texttt{Total Bsmt SF}: total basement area
    \item \texttt{Lot Area}: size of the lot
    \item \texttt{Full Bath}: number of full bathrooms
    \item \texttt{Garage Area}: size of the garage (square feet)
    \item \texttt{Garage Cars}: garage capacity (number of cars)
    \item \texttt{Garage Yr Blt}: year the garage was built
    \item \texttt{Year Built}: construction year of the house
    \item \texttt{Year Remod/Add}: year of the most recent remodeling
    \item \texttt{Utilities}: type of utilities available
\end{itemize}

These attributes quantify the amount of usable space and reflect the structural age of the property.

% ---------------------------------------

\subsubsection{Quality assessments}

The dataset includes several ordinal ratings assigned by professional assessors:

\begin{itemize}
    \item \texttt{Overall Qual}: overall material and finish quality
    \item \texttt{Kitchen Qual}: quality of kitchen materials
    \item \texttt{ExterQual}: exterior materials and workmanship
    \item \texttt{BsmtQual}: quality of basement materials
\end{itemize}

These variables summarize qualitative features that are not captured by size alone.

% ---------------------------------------

\subsubsection{Locational and timing information}

\begin{itemize}
    \item \texttt{Neighborhood}: categorical variable identifying the physical location within the city of Ames
    \item \texttt{MS Zoning}: zoning classification (e.g., low--density residential, medium--density residential, commercial)
    \item \texttt{Year Sold}: year the property was sold
\end{itemize}

These variables incorporate locational amenities and neighbourhood--level characteristics that influence market value.

% ---------------------------------------





% ================================
% Model Specification
% ================================
\section{Model specification and estimation}

The aim of this section is to construct a multiple linear regression model in order to explain the variation in the sale price of residential properties.

The dependent variable is \texttt{SalePrice}, while the set of regressors includes the structural, qualitative, and locational characteristics identified in the previous section.

% ---------------------------------------

\subsection{model specification}

The regression model is specified as follows:

\[
    \begin{aligned}
        \texttt{[SalePrice]}_i & =
        \beta_0
        + \beta_1\,\texttt{[Gr Liv Area]}_i
        + \beta_2\,\texttt{[1st Flr SF]}_i
        + \beta_3\,\texttt{[Total Bsmt SF]}_i                                    \\
                               & \quad + \beta_4\,\texttt{[Lot Area]}_i
        + \beta_5\,\texttt{[Full Bath]}_i
        + \beta_6\,\texttt{[Garage Area]}_i                                      \\
                               & \quad + \beta_7\,\texttt{[Garage Cars]}_i
        + \beta_8\,\texttt{[Garage Yr Blt]}_i
        + \beta_9\,\texttt{[Year Built]}_i                                       \\
                               & \quad + \beta_{10}\,\texttt{[Year Remod/Add]}_i
        + \beta_{12}\,\texttt{[Overall Qual]}_i
        + \beta_{13}\,\texttt{[Kitchen Qual]}_i                                  \\
                               & \quad + \beta_{14}\,\texttt{[Exter Qual]}_i
        + \beta_{15}\,\texttt{[Bsmt Qual]}_i
        + \beta_{16}\,\texttt{[Neighborhood]}_i
        + \varepsilon_i
    \end{aligned}
\]

where:

\begin{itemize}
    \item $\beta_0$ is the intercept;
    \item the $\beta_k$ denotes the coefficient associated with regressor $k$, \quad $\forall k = 1, \ldots, 16$
    \item $\varepsilon_i$ is the error term capturing unobserved factors;
    \item the variables \texttt{Overall Qual}, \texttt{Kitchen Qual}, \texttt{Exter Qual}, \texttt{Bsmt Qual} and \texttt{Neighborhood} are treated as categorical factors and encoded via dummy variables
\end{itemize}

% ---------------------------------------


\subsection{Model assumptions}

Our multiple linear regression model is estimated under the following assumptions:

\paragraph{Linearity of the conditional mean.}
\[
    \mathbb{E}[\varepsilon_i \mid X_i] = 0
    \quad \Longleftrightarrow \quad
    \mathbb{E}[Y_i \mid X_i]
    = \beta_0 + \beta_1 X_{i1} + \cdots + \beta_p X_{ip}.
\]
This assumption implies that all systematic variation in the dependent variable is captured by the regressors.

\paragraph{Independent and identically distributed observations.}
\[
    (Y_i, X_i) \;\perp\!\!\!\perp\; (Y_j, X_j)
    \qquad \text{for } i \neq j,
\]
and all observations are drawn from the same population distribution.
This corresponds to the standard \textit{i.i.d.} sampling framework.

\paragraph{Finite fourth moments.}
\[
    \mathbb{E}[X_{ik}^4] < \infty
    \qquad \text{and} \qquad
    \mathbb{E}[\varepsilon_i^4] < \infty.
\]
This condition ensures the applicability of asymptotic results and prevents extreme observations from dominating the estimation.

% ---------------------------------------

\subsection{Model implementation and estimation}

Here we report the full R code used for the estimation of the baseline multiple linear regression model, including data preparation and variable renaming.

\begin{lstlisting}[style=rstyle]
library(dplyr)

# First, we load the dataset and rename
# the variables into more convenient names
ames <- read.csv("Amespug.csv")
ames_clean <- ames %>%
    rename(
        GrLivArea     = `Gr.Liv.Area`,
        FirstFlrSF    = `X1st.Flr.SF`,
        TotalBsmtSF   = `Total.Bsmt.SF`,
        LotArea       = `Lot.Area`,
        FullBath      = `Full.Bath`,
        GarageArea    = `Garage.Area`,
        GarageCars    = `Garage.Cars`,
        GarageYrBlt   = `Garage.Yr.Blt`,
        YearBuilt     = `Year.Built`,
        YearRemodAdd  = `Year.Remod.Add`,
        OverallQual   = `Overall.Qual`,
        KitchenQual   = `Kitchen.Qual`,
        ExterQual     = `Exter.Qual`,
        BsmtQual      = `Bsmt.Qual`,
        Neighborhood  = Neighborhood
    )

# Linear regression
model <- lm(
    SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF + LotArea +
        FullBath + GarageArea + GarageCars + GarageYrBlt +
        YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual +
        Neighborhood,
    data = ames_clean
)

# Results
summary(model)
\end{lstlisting}


\begin{lstlisting}[style=routput]
Call:
lm(formula = SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF +
    LotArea + FullBath + GarageArea + GarageCars + GarageYrBlt +
    YearBuilt + YearRemodAdd + OverallQual + KitchenQual + ExterQual +
    BsmtQual + Neighborhood, data = ames_clean)

Residuals:
    Min      1Q  Median      3Q     Max
-458670  -12548     282   12557  233675

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)
(Intercept)         -7.243e+05  1.326e+05  -5.463 5.11e-08 ***
GrLivArea            4.356e+01  2.052e+00  21.226  < 2e-16 ***
FirstFlrSF           8.657e+00  3.725e+00   2.324 0.020179 *
TotalBsmtSF          9.625e+00  3.423e+00   2.812 0.004955 **
LotArea              6.445e-01  8.528e-02   7.557 5.62e-14 ***
FullBath            -2.970e+03  1.688e+03  -1.760 0.078553 .
GarageArea           2.026e+01  6.717e+00   3.017 0.002577 **
GarageCars           6.594e+03  1.951e+03   3.379 0.000737 ***
GarageYrBlt         -6.674e+01  4.839e+01  -1.379 0.167965
YearBuilt            2.262e+02  5.792e+01   3.905 9.66e-05 ***
YearRemodAdd         2.445e+02  4.579e+01   5.339 1.01e-07 ***
OverallQual          1.199e+04  8.413e+02  14.248  < 2e-16 ***
KitchenQualFa       -3.413e+04  5.877e+03  -5.808 7.08e-09 ***
KitchenQualGd       -2.820e+04  3.201e+03  -8.811  < 2e-16 ***
KitchenQualPo       -5.463e+04  3.143e+04  -1.738 0.082314 .
KitchenQualTA       -3.437e+04  3.581e+03  -9.597  < 2e-16 ***
ExterQualFa         -4.054e+04  8.993e+03  -4.508 6.83e-06 ***
ExterQualGd         -2.722e+04  4.118e+03  -6.609 4.66e-11 ***
ExterQualTA         -2.682e+04  4.665e+03  -5.749 9.98e-09 ***
BsmtQualFa          -3.179e+04  5.268e+03  -6.034 1.82e-09 ***
BsmtQualGd          -3.014e+04  2.833e+03 -10.639  < 2e-16 ***
BsmtQualPo          -2.953e+04  2.253e+04  -1.311 0.189988
BsmtQualTA          -2.952e+04  3.540e+03  -8.337  < 2e-16 ***
NeighborhoodBlueste -7.475e+03  1.152e+04  -0.649 0.516562
NeighborhoodBrDale  -1.612e+04  8.670e+03  -1.860 0.063023 .
NeighborhoodBrkSide  3.168e+03  7.520e+03   0.421 0.673574
NeighborhoodClearCr  2.066e+04  7.975e+03   2.591 0.009618 **
NeighborhoodCollgCr  9.051e+03  6.240e+03   1.450 0.147055
NeighborhoodCrawfor  2.810e+04  7.158e+03   3.926 8.86e-05 ***
NeighborhoodEdwards -1.040e+04  6.894e+03  -1.508 0.131716
NeighborhoodGilbert  4.753e+03  6.486e+03   0.733 0.463774
NeighborhoodGreens   1.412e+04  1.249e+04   1.131 0.258345
NeighborhoodGrnHill  1.403e+05  3.127e+04   4.486 7.57e-06 ***
NeighborhoodIDOTRR  -6.567e+03  7.860e+03  -0.835 0.403551
NeighborhoodLandmrk -1.301e+04  3.129e+04  -0.416 0.677492
NeighborhoodMeadowV -9.408e+03  8.943e+03  -1.052 0.292867
NeighborhoodMitchel  2.414e+03  6.884e+03   0.351 0.725840
NeighborhoodNAmes    3.094e+03  6.592e+03   0.469 0.638863
NeighborhoodNoRidge  6.035e+04  7.163e+03   8.426  < 2e-16 ***
NeighborhoodNPkVill -5.402e+03  8.941e+03  -0.604 0.545811
NeighborhoodNridgHt  3.070e+04  6.575e+03   4.670 3.16e-06 ***
NeighborhoodNWAmes   2.648e+03  6.736e+03   0.393 0.694222
NeighborhoodOldTown -9.368e+03  7.297e+03  -1.284 0.199312
NeighborhoodSawyer   4.100e+03  6.884e+03   0.596 0.551549
NeighborhoodSawyerW  2.807e+03  6.660e+03   0.421 0.673440
NeighborhoodSomerst  1.341e+04  6.358e+03   2.109 0.035067 *
NeighborhoodStoneBr  5.038e+04  7.401e+03   6.807 1.23e-11 ***
NeighborhoodSWISU   -2.665e+03  8.445e+03  -0.315 0.752407
NeighborhoodTimber   1.464e+04  7.001e+03   2.092 0.036558 *
NeighborhoodVeenker  2.531e+04  8.710e+03   2.905 0.003697 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '. 0.1 ' ' 1

Residual standard error: 30630 on 2655 degrees of freedom
  (225 observations deleted due to missingness)
Multiple R-squared:  0.8543,	Adjusted R-squared:  0.8516
F-statistic: 317.8 on 49 and 2655 DF,  p-value: < 2.2e-16
\end{lstlisting}





% ================================
% Estimation and Results
% ================================
\subsection{Interpretation of the regression output}

The OLS regression is estimated on 2{,}770 observations.\footnote{The original dataset contains 2{,}930 observations; 225 are removed due to missing values in the selected regressors.}
The dependent variable is \texttt{SalePrice}, while the regressors include size-related variables, quality indicators, age and renovation variables, and a set of dummy variables for \texttt{OverallQual}, \texttt{KitchenQual}, \texttt{ExterQual}, \texttt{BsmtQual} and \texttt{Neighbourhood}.

\subsubsection{Overall Fit of the model}

The model exhibits a high goodness of fit:

\begin{itemize}
    \item $\text{R-squared} = 0.8543$
    \item $\text{Adjusted R-squared} = 0.8516$
\end{itemize}

This means that approximately 85\% of the variation in house prices in Ames is explained by the regressors included in the model.

The overall \textit{F}-statistic is 317.8 (with $p < 2.2\times10^{-16}$), strongly rejecting the null hypothesis that all slope coefficients are jointly equal to zero.
Thus, the explanatory variables collectively have a statistically significant effect on \texttt{SalePrice}.

\subsubsection{Interpretation of the main coefficients}

The first group of regressors captures size, structural characteristics, and age.
The main findings are summarised below.

\paragraph{Living area and basement space.}
\texttt{GrLivArea} has an estimated coefficient of approximately $43.6$ (p~$<2\times10^{-16}$).
This implies that, \textit{ceteris paribus}, an additional square foot of above-ground living area increases the expected sale price by about \$44.

The coefficient on \texttt{TotalBsmtSF} is about $9.6$ (p~$=0.0049$), indicating that basement space is also valued by the market, though less than above-ground living area.

\paragraph{Lot size.}
\texttt{LotArea} enters with a small but positive and highly significant coefficient ($0.64$, p~$<10^{-13}$), suggesting that marginal increases in lot size add value, though at a much lower rate than interior space.

\paragraph{Bathrooms and garage capacity.}
The coefficient on \texttt{FullBath} is negative ($-2{,}970$, p~$=0.078$), borderline significant.
This counterintuitive sign is likely explained by collinearity: once living area and quality are included, an additional bathroom at fixed size may not capture higher quality \cite{DeCock2011}.

\texttt{GarageArea} and \texttt{GarageCars} are both positive and significant ($20.3$ and $6{,}594$ respectively), indicating that larger garages and capacity for more vehicles contribute positively to sale price.

\paragraph{Construction and renovation year.}
\texttt{YearBuilt} ($226$, p~$9.7\times10^{-5}$) and \texttt{YearRemodAdd} ($244$, p~$10^{-7}$) are both positive and highly significant: newer homes and recently renovated properties command higher prices, consistent with depreciation and modernization effects.

\paragraph{Quality indicators.}
\texttt{OverallQual} is one of the strongest predictors in the model, with an estimated coefficient of roughly $11{,}990$ (p~$<2\times10^{-16}$).
A one-point increase in overall quality raises the predicted sale price by about \$12k, confirming the central importance of quality emphasised in the real estate house pricing literature.

The categorical quality variables \texttt{KitchenQual}, \texttt{ExterQual} and \texttt{BsmtQual} are encoded through dummy variables.
Since the reference category corresponds to the highest quality level, most dummy coefficients are negative and highly significant, reflecting the price discounts associated with lower kitchen, exterior or basement quality.

\paragraph{Neighbourhood effects.}
A large block of coefficients corresponds to neighbourhood dummies.
Some neighbourhoods show large, positive and highly significant premia relative to the omitted reference category — for example:

\begin{itemize}
    \item \texttt{NeighborhoodGrnHill}: $+140{,}300$ (p~$7.6\times10^{-6}$)
    \item \texttt{NeighborhoodNoRidge}: $+60{,}350$ (p~$<2\times10^{-16}$)
    \item \texttt{NeighborhoodNridgHt}: $+30{,}700$ (p~$3.2\times10^{-6}$)
    \item \texttt{NeighborhoodStoneBr}: $+50{,}380$ (p~$1.2\times10^{-11}$)
\end{itemize}

These coefficients indicate that location plays a substantial role in determining housing values, even after controlling for structure, size and quality.

Other neighbourhoods show coefficients statistically indistinguishable from zero, indicating that once structural and qualitative variables are controlled for, price differences across those areas are not significant.



% ================================
% Diagnostics
% ================================
\section{Diagnostic analysis}

\subsection{Perfect collinearity}

Perfect collinearity arises when one explanatory variable can be expressed as an exact linear combination of others.
Among all possible specification errors, this is the most severe, because perfect collinearity makes the OLS estimator \textit{impossible} to compute: the design matrix becomes singular and the matrix $(X^\top X)^{-1}$ required for OLS does not exist.
Other specification issues (such as omitted variables, functional form errors, or heteroskedasticity) typically affect the desirable properties of the OLS estimator under the Gauss–Markov assumptions, but do not prevent its computation. Perfect collinearity, instead, makes estimation itself undefined.

In the specification of our main model, perfect collinearity does not occur.
However, the \textit{Ames Housing Dataset} contains a well-known identity that can generate perfect collinearity if the analyst is not careful.

Consider the four area variables:
\[
    \texttt{GrLivArea} = \texttt{FirstFlrSF} + \texttt{SecondFlrSF} + \texttt{LowQualFinSF}
\]

If all observations satisfy this identity exactly, which is almost always the case in the dataset, then including all four variables simultaneously in a regression introduces an exact linear dependence.
In such a case, OLS cannot distinguish the marginal contribution of each component because they lie on the same hyperplane in the regressor space.

% ---------------------------------------


\begin{lstlisting}[style=rstyle]
# Perfect collinearity test
ames_multicollineareperfetto <- ames %>%
    rename(
        GrLivArea    = `Gr.Liv.Area`,
        FirstFlrSF   = `X1st.Flr.SF`,
        SecondFlrSF  = `X2nd.Flr.SF`,
        LowQualFinSF = `Low.Qual.Fin.SF`,
        TotalBsmtSF  = `Total.Bsmt.SF`,
        LotArea      = `Lot.Area`,
        FullBath     = `Full.Bath`,
        GarageArea   = `Garage.Area`,
        GarageCars   = `Garage.Cars`,
        GarageYrBlt  = `Garage.Yr.Blt`,
        YearBuilt    = `Year.Built`,
        YearRemodAdd = `Year.Remod.Add`,
        OverallQual  = `Overall.Qual`,
        KitchenQual  = `Kitchen.Qual`,
        ExterQual    = `Exter.Qual`,
        BsmtQual     = `Bsmt.Qual`,
        Neighborhood = `Neighborhood`,
        MSZoning     = `MS.Zoning`,
        Utilities    = `Utilities`
    )

# Linear model with potential perfect collinearity
modelmulticollperf <- lm(
    SalePrice ~ GrLivArea + FirstFlrSF + SecondFlrSF + LowQualFinSF +
        TotalBsmtSF + LotArea + FullBath + GarageArea + GarageCars +
        GarageYrBlt + YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual +
        Neighborhood + MSZoning + Utilities,
    data = ames_multicollineareperfetto
)

summary(modelmulticollperf)
\end{lstlisting}

% ---------------------------------------

\begin{lstlisting}[style=routput]
Call:
lm(formula = SalePrice ~ GrLivArea + FirstFlrSF + SecondFlrSF +
    LowQualFinSF + TotalBsmtSF + LotArea + FullBath + GarageArea +
    GarageCars + GarageYrBlt + YearBuilt + YearRemodAdd + OverallQual +
    KitchenQual + ExterQual + BsmtQual + Neighborhood + MSZoning +
    Utilities, data = ames_multicollineareperfetto)

Residuals:
    Min      1Q  Median      3Q     Max
-457007  -12709     135   12330  233868

Coefficients: (1 not defined because of singularities)
                      Estimate Std. Error t value Pr(>|t|)
(Intercept)         -7.548e+05  1.344e+05  -5.617 2.15e-08 ***
GrLivArea            2.280e+01  1.433e+01   1.591 0.111753
FirstFlrSF           2.976e+01  1.484e+01   2.005 0.045045 *
SecondFlrSF          2.088e+01  1.441e+01   1.449 0.147467
LowQualFinSF                NA         NA      NA       NA
TotalBsmtSF          9.048e+00  3.423e+00   2.644 0.008251 **
LotArea              6.469e-01  8.584e-02   7.535 6.64e-14 ***
FullBath            -3.158e+03  1.688e+03  -1.871 0.061456 .
GarageArea           1.807e+01  6.767e+00   2.670 0.007621 **
GarageCars           7.132e+03  1.962e+03   3.635 0.000283 ***
GarageYrBlt         -6.638e+01  4.847e+01  -1.370 0.170952
YearBuilt            2.351e+02  5.839e+01   4.026 5.84e-05 ***
YearRemodAdd         2.398e+02  4.571e+01   5.246 1.68e-07 ***
OverallQual          1.197e+04  8.430e+02  14.201  < 2e-16 ***
KitchenQualFa       -3.396e+04  5.864e+03  -5.792 7.77e-09 ***
KitchenQualGd       -2.793e+04  3.191e+03  -8.751  < 2e-16 ***
KitchenQualPo       -5.436e+04  3.132e+04  -1.736 0.082768 .
KitchenQualTA       -3.386e+04  3.574e+03  -9.473  < 2e-16 ***
ExterQualFa         -3.919e+04  9.015e+03  -4.347 1.43e-05 ***
ExterQualGd         -2.738e+04  4.105e+03  -6.670 3.10e-11 ***
ExterQualTA         -2.738e+04  4.653e+03  -5.884 4.50e-09 ***
BsmtQualFa          -3.345e+04  5.268e+03  -6.350 2.53e-10 ***
BsmtQualGd          -3.063e+04  2.828e+03 -10.834  < 2e-16 ***
BsmtQualPo          -2.087e+04  2.375e+04  -0.879 0.379561
BsmtQualTA          -3.018e+04  3.538e+03  -8.531  < 2e-16 ***
...
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 30520 on 2647 degrees of freedom
(225 observations deleted due to missingness)
Multiple R-squared:  0.8558,    Adjusted R-squared:  0.8527
F-statistic: 275.6 on 57 and 2647 DF,  p-value: < 2.2e-16
\end{lstlisting}


% ---------------------------------------

The standard remedy is to remove \textit{one} of the linearly dependent variables.
Since the three components sum exactly to \texttt{GrLivArea}, the choice of which variable to drop is irrelevant from an informational standpoint: the remaining variables still span the same linear space.

Statistical software such as \texttt{R} automatically detects this issue and removes one of the problematic regressors.
In our collinearity test, \texttt{R} excluded \texttt{LowQualFinSF}, which can be verified from the regression output: the estimated coefficient and its standard error appear as \texttt{NA}, accompanied by the message \emph{``1 not defined because of singularities''}.
This confirms that the dataset indeed contains an exact linear relationship among area variables, and that perfect collinearity is handled automatically by the software when these variables are included together.

% ---------------------------------------

\subsection{Imperfect collinearity: \textit{Variance Inflation Factors}}

Imperfect, or near, collinearity arises when two or more explanatory variables are highly correlated, although not perfectly linearly dependent.
In this situation, OLS estimation is still feasible, but the variance of the affected coefficients becomes inflated.
As a consequence, standard errors increase, leading to wider confidence intervals and less informative hypothesis tests.
Inferences about the individual significance of regressors may therefore become unreliable, even when the variables are conceptually relevant.

A common solution consists in removing or combining regressors that are strongly correlated with others.
To detect the presence and severity of near-collinearity, we rely on the \textit{Variance Inflation Factor} (VIF), which corresponds to the second term in the variance of an OLS coefficient and serves as an alternative to examining pairwise sample correlations among regressors.

For a given regressor $X_j$, the VIF is defined as:

\[
    \text{VIF}_j = \frac{1}{1 - R_j^2}
\]

where $R_j^2$ is the coefficient of determination from the auxiliary regression of $X_j$ on the remaining regressors.
A large VIF value indicates that $X_j$ is strongly correlated with other regressors, implying increased variance of its estimated coefficient and, consequently, less precise inference.

% ---------------------------------------

\begin{lstlisting}[style=rstyle]
library(car)
vif_values <- vif(model)
print(vif_values)
\end{lstlisting}

% ---------------------------------------

\begin{lstlisting}[style=routput]
                  GVIF Df GVIF^(1/(2*Df))
GrLivArea     3.043312  1        1.744509
FirstFlrSF    6.121783  1        2.474224
TotalBsmtSF   5.693781  1        2.386165
LotArea       1.358761  1        1.165659
FullBath      2.492432  1        1.578744
GarageArea    4.642314  1        2.154603
GarageCars    4.666852  1        2.160290
GarageYrBlt   4.414460  1        2.101062
YearBuilt     8.445562  1        2.906125
YearRemodAdd  2.536321  1        1.592583
OverallQual   3.741132  1        1.934201
KitchenQual   5.173766  4        1.228078
ExterQual     6.257313  3        1.357473
BsmtQual      7.135004  4        1.278422
Neighborhood 41.329522 27        1.071348
\end{lstlisting}

The literature offers different threshold values for interpreting VIFs, with common rules of thumb ranging from 5 to 10 as indicators of problematic collinearity.
In models including categorical variables with more than two levels, \texttt{R} reports the \textit{Generalized Variance Inflation Factor} (GVIF), an extension of the VIF that properly accounts for multiple degrees of freedom.
This adjustment is necessary because a categorical variable with $k$ levels expands into $(k{-}1)$ dummy variables, for which the classical VIF cannot be computed directly.

For variables with one degree of freedom, GVIF coincides with the standard VIF. Viceversa, for categorical regressors with more than one degree of freedom, GVIF must be transformed using the formula:

\[
    \text{GVIF}^{\,1/(2\,\text{df})}
\]

This yields a value comparable to the standard VIF, which explains why some categorical variables appear to have extremely high GVIFs: the large values simply reflect their number of dummy variables rather than true collinearity issues.

For example, \texttt{Neighborhood} exhibits a very large GVIF (41.32), but once transformed it corresponds to a reasonable VIF of approximately 1.07.

Since, in our model, none of the transformed VIF values exceeds the common threshold of 10, nor comes close to it, we conclude that collinearity is not a serious concern for our current specification, and all the included regressors can be safely retained.


% ---------------------------------------

\subsection{Structural stability: \textit{Chow test} around the 2008 financial crisis}
\label{sec:chow-test}

In this section we investigate whether the relationship between the explanatory variables and \texttt{SalePrice} remained stable over time.
Structural changes in the coefficients may arise for several reasons, and sharp economic events, such as financial crises, are among the most common sources of such instability.
Since our dataset covers housing transactions between 2006 and 2010, it is natural to test for a structural break around 2008, the year associated with the outbreak of the Global Financial Crisis. The Chow test evaluates precisely this hypothesis.

Let $RSS_P$ and $RSS_C$ denote the residual sum of squares of the model estimated separately on the pre-crisis and the crisis/post-crisis subsamples, and let $RSS_{P \cup C}$ be the residual sum of squares of the model estimated on the full pooled sample. Denoting by $k$ the number of estimated parameters (including the intercept), and by $n_P$ and $n_C$ the sample sizes of the two subsamples, the Chow test statistic is:

\[
    F \;=\;
    \frac{
        RSS_{P \cup C} - \bigl(RSS_P + RSS_C\bigr)
    }{
        k
    }
    \Bigg/
    \frac{
        RSS_P + RSS_C
    }{
        n_P + n_C - 2k
    },
\]

which, under the null hypothesis of parameter stability, follows an $F$-distribution with $(k, n_P + n_C - 2k)$ degrees of freedom.

In practice, we rely on the implementation provided by the \texttt{strucchange} package in \texttt{R}, which evaluates a Chow-type test at the break point corresponding to the first sale in 2008.

% ---------------------------------------

\vspace{0.2cm}
\begin{lstlisting}[style=rstyle]
# Chow-type structural stability test
library(sandwich)
library(strucchange)

# Ensure ordered factors for quality variables
ames_clean$OverallQual <- ordered(ames_clean$OverallQual, levels = 1:10)
ames_clean$KitchenQual <- ordered(
    ames_clean$KitchenQual,
    levels = c("Po", "Fa", "TA", "Gd", "Ex")
)
ames_clean$ExterQual <- ordered(
    ames_clean$ExterQual,
    levels = c("Po", "Fa", "TA", "Gd", "Ex")
)
ames_clean$BsmtQual <- ordered(
    ames_clean$BsmtQual,
    levels = c("Po", "Fa", "TA", "Gd", "Ex")
)

# Order data by year of sale
ames_ordered <- ames_clean[order(ames_clean$Yr.Sold)]

# Baseline model for structural break test (without Neighborhood)
modelordered <- lm(
    SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF + LotArea +
        FullBath + GarageArea + GarageCars + GarageYrBlt +
        YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual,
    data = ames_ordered
)

# Break point: first observation with Yr.Sold == 2008
break_point <- min(which(ames_ordered$Yr.Sold == 2008))

# Chow-type test at the given break point
chow_test <- sctest(modelordered, type = "Chow", point = break_point)
print(chow_test)
\end{lstlisting}

\begin{lstlisting}[style=routput]
M-fluctuation test

data:  modelordered
f(efp) = 1.3035, p-value = 0.8746
\end{lstlisting}


\vspace{2.5cm}
\begin{lstlisting}[style=rstyle]
# Separate models pre- and post-2008 (including Neighborhood)
model_pre2008 <- lm(
    SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF + LotArea +
        FullBath + GarageArea + GarageCars + GarageYrBlt +
        YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual +
        Neighborhood,
    data = subset(ames_clean, Yr.Sold <= 2008)
)

summary(model_pre2008)
\end{lstlisting}

\begin{lstlisting}[style=routput]
Call:
lm(formula = SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF +
    LotArea + FullBath + GarageArea + GarageCars + GarageYrBlt +
    YearBuilt + YearRemodAdd + OverallQual + KitchenQual + ExterQual +
    BsmtQual + Neighborhood, data = subset(ames_clean, Yr.Sold <=
    2008))

Residuals:
    Min      1Q  Median      3Q     Max
-403392  -13136     131   11787  214650

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)
(Intercept)         -6.937e+05  1.634e+05  -4.244 2.31e-05 ***

...
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 31660 on 1738 degrees of freedom
  (147 observations deleted due to missingness)
Multiple R-squared:  0.8485,	Adjusted R-squared:  0.8438
F-statistic:   177 on 55 and 1738 DF,  p-value: < 2.2e-16
\end{lstlisting}

\begin{lstlisting}[style=rstyle]
model_post2008 <- lm(
    SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF + LotArea +
        FullBath + GarageArea + GarageCars + GarageYrBlt +
        YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual +
        Neighborhood,
    data = subset(ames_clean, Yr.Sold > 2008)
)

summary(model_post2008)
\end{lstlisting}

\begin{lstlisting}[style=routput]
Call:
lm(formula = SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF +
    LotArea + FullBath + GarageArea + GarageCars + GarageYrBlt +
    YearBuilt + YearRemodAdd + OverallQual + KitchenQual + ExterQual +
    BsmtQual + Neighborhood, data = subset(ames_clean, Yr.Sold >
    2008))

Residuals:
    Min      1Q  Median      3Q     Max
-113146  -11817    1258   11907  184243

Coefficients:
                      Estimate Std. Error t value Pr(>|t|)
(Intercept)         -1.244e+06  2.032e+05  -6.121 1.41e-09 ***

...
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 25200 on 857 degrees of freedom
  (78 observations deleted due to missingness)
Multiple R-squared:  0.9026,	Adjusted R-squared:  0.8966
F-statistic: 149.9 on 53 and 857 DF,  p-value: < 2.2e-16
\end{lstlisting}

% ---------------------------------------

The test yields a very large p-value (0.8746), so we fail to reject the null hypothesis of parameter stability.
At first sight, this may appear counter--intuitive, given that the financial crisis was closely linked to a speculative bubble in housing markets.
However, this result suggests an important distinction: the crisis may have shifted the \emph{level} of house prices without altering the \emph{structure} of the underlying pricing relationship.

To assess this interpretation, we estimate two separate regressions:

\begin{itemize}
    \item \textbf{pre-crisis period}: houses sold between 2006 and 2008
    \item \textbf{post-crisis period}: houses sold between 2009 and 2010
\end{itemize}

Comparing the estimated intercepts across the two models shows that they differ substantially, with the post--crisis regression exhibiting a markedly lower intercept.
This indicates that the crisis primarily caused a downward shift in the overall price level, while the marginal effects of structural and qualitative characteristics remained broadly stable.

In other words, the crisis affected \emph{how much} houses sold for, but not \emph{why} certain houses sold for more than others.
The fundamental price determinants captured by our model appear structurally robust before and after 2008.

% ---------------------------------------

\subsection{Functional form misspecification: \textit{RESET test}}

We now investigate whether the linear functional form assumed in our baseline specification is adequate.
A classical diagnostic tool for this purpose is the \textit{Ramsey RESET test}, which evaluates whether nonlinear combinations of the fitted values possess explanatory power beyond the original regressors.
A low p--value indicates rejection of the null hypothesis of correct functional form.

In our case, the \textit{RESET test} produces a very small p--value, leading us to reject the null hypothesis of linearity.
This result suggests the presence of functional form misspecification.
Nonlinearities may arise either from structural breaks or from omitted variables.
As discussed in Section~\ref{sec:chow-test}, the Chow test shows no evidence of a structural break around the 2008 financial crisis, which we consider the most plausible breakpoint.
Therefore, it is reasonable to attribute the nonlinearity detected by the \textit{RESET test} to omitted relevant terms, such as interactions or nonlinear transformations of existing regressors.

\paragraph{Ordinal regressors and nonlinearity.}

A central issue concerns the ordinal regressors included in the model, namely \texttt{OverallQual}, \texttt{KitchenQual}, \texttt{ExterQual}, and \texttt{BsmtQual}.
Although \texttt{R} initially treats these variables as unordered categorical factors, they possess a meaningful ranking from \textit{``Poor''} to \textit{``Excellent''}.
By explicitly transforming them into ordered factors, the model is able to capture potential nonlinear effects across successive quality levels rather than treating the dummy coefficients as independent of one another.

The variable \texttt{OverallQual} deserves particular attention.
Its numeric scale from 1 to 10 might appear continuous, but the values represent subjective assessments of overall quality rather than cardinal quantities.
Treating it as an ordered factor instead of a numerical variable allows the model to accommodate nonlinear, possibly non-monotonic differences across quality levels.


\paragraph{Logarithmic transformations.}

Finally, we apply logarithmic transformations to the dependent variable and several continuous regressors.
This choice is supported by economic reasoning: in a log--log specification, coefficients represent elasticities (percentage changes in \texttt{SalePrice} associated with percentage changes in the regressors); it also helps capture diminishing marginal effects.
For example, a 1\% increase in livable area is likely to have a larger impact on the price of a small house than on the price of a very large one, where additional space contributes less to perceived value relative to other features such as quality.

Taken together, these considerations support the conclusion that the baseline linear specification is not sufficiently flexible and that incorporating ordered factors, nonlinear transformations, and economically meaningful interactions is both statistically justified and economically interpretable.


\paragraph{Interaction terms.}

To address additional sources of nonlinearity, we also introduce the following economically motivated interaction term: \(\texttt{GrLivArea} \times \texttt{OverallQual}\).

This interaction has a clear economic interpretation.
A large but low-quality house may be worth less than a smaller but high-quality one; without the interaction between livable area and quality, this effect would be entirely missed by a linear model.

% ---------------------------------------


\begin{lstlisting}[style=rstyle]
library(lmtest)

# Transform ordinal variables
ames_clean$OverallQual <- ordered(ames_clean$OverallQual, levels = 1:10)
ames_clean$KitchenQual <- ordered(
    ames_clean$KitchenQual,
    levels = c("Po", "Fa", "TA", "Gd", "Ex")
)
ames_clean$ExterQual <- ordered(
    ames_clean$ExterQual,
    levels = c("Po", "Fa", "TA", "Gd", "Ex")
)
ames_clean$BsmtQual <- ordered(
    ames_clean$BsmtQual,
    levels = c("Po", "Fa", "TA", "Gd", "Ex")
)

# Baseline model
model <- lm(
    SalePrice ~ GrLivArea + FirstFlrSF + TotalBsmtSF + LotArea +
        FullBath + GarageArea + GarageCars + GarageYrBlt +
        YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual +
        Neighborhood,
    data = ames_clean
)

resettest(model)
\end{lstlisting}

\begin{lstlisting}[style=routput]
RESET test for model:
RESET = 235.08, df1 = 2, df2 = 2646, p-value < 2.2e-16
\end{lstlisting}

% ---------------------------------------


\begin{lstlisting}[style=rstyle]
# Log-linear model
model_log <- lm(
    log(SalePrice) ~ log(GrLivArea) + log(FirstFlrSF) + log(TotalBsmtSF) +
        log(LotArea) + FullBath + GarageArea + GarageCars +
        GarageYrBlt + YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual + Neighborhood,
    data = ames_clean
)

resettest(model_log)
\end{lstlisting}

\begin{lstlisting}[style=routput]
RESET test for log-model:
RESET = 30.217, df1 = 2, df2 = 2646, p-value = 1.058e-13
\end{lstlisting}

% ---------------------------------------

\begin{lstlisting}[style=rstyle]
# Log-model with interactions
model_transformato_reset <- lm(
    log(SalePrice) ~ log(GrLivArea) + log(FirstFlrSF) + log(TotalBsmtSF) +
        log(LotArea) + FullBath + GarageArea + GarageCars +
        YearBuilt + YearRemodAdd + OverallQual +
        KitchenQual + ExterQual + BsmtQual + Neighborhood +
        GrLivArea:OverallQual,
    data = ames_clean
)

resettest(model_transformato_reset)
\end{lstlisting}

\begin{lstlisting}[style=routput]
RESET test for log-model with interactions:
RESET = 0.064315, df1 = 2, df2 = 2780, p-value = 0.9377
\end{lstlisting}

% ---------------------------------------


\subsection{Heteroskedasticity and independence of residuals}

The \textit{Gauss--Markov theorem}, beyond linear--conditional expectation of \texttt{SalePrice}, relies on two crucial assumptions:

\begin{itemize}
    \item homoskedasticity of the error term
    \item lack of serial correlation among residuals
\end{itemize}

If these assumptions are violated, the OLS estimator remains unbiased but it is no longer efficient, and standard inferential procedures based on classical standard errors become unreliable.

\subsubsection{Heteroskedasticity}

Given that our dataset is cross--sectional, heteroskedasticity (non--constant error variance across observations) is a natural concern.
To formally assess this, we conduct the \textit{White test} for heteroskedasticity.
This test evaluates whether the variance of the residuals depends on the regressors, their squares, or their pairwise interactions.
Significant coefficients in the auxiliary regression imply that the error variance systematically varies with one or more explanatory variables.

\begin{lstlisting}[style=rstyle]
library(whitestrap)
white_test(model_transformato_reset)
\end{lstlisting}

\begin{lstlisting}[style=routput]
White's test results

Null hypothesis: Homoskedasticity of the residuals
Alternative hypothesis: Heteroskedasticity of the residuals
Test Statistic: 155.73
P-value: 0
\end{lstlisting}

The \textit{White test} produces a very small p--value, leading us to reject the null hypothesis of homoskedasticity.
We therefore conclude that heteroskedasticity is present in the model.

A standard remedy is to compute heteroskedasticity--robust standard errors, by using the HAC (\textit{Heteroskedasticity and Autocorrelation Consistent}) estimator.
Using robust standard errors allows us to maintain valid inference even when the homoskedasticity assumption is violated.

\begin{lstlisting}[style=rstyle]
library(sandwich)
library(lmtest)

# Using HAC estimator for standard errors
vcov_hac <- vcovHAC(model)
coeftest(model_transformato_reset, vcov. = vcov_hac)
summary(model_transformato_reset)
\end{lstlisting}

% \begin{lstlisting}[style=routput]
% pippo
% \end{lstlisting}

\subsubsection{Independence of residuals}

Testing for serial correlation in a cross--sectional framework is generally inappropriate, since the ordering of observations does not correspond to a meaningful time dimension.
The \textit{Durbin--Watson test}, in particular, is designed for time--series or panel data where residuals may be correlated with their past values.

To investigate whether meaningful temporal autocorrelation could be identified in this dataset, we attempted to construct a pseudo--panel by identifying houses that appear multiple times (same \texttt{PID}) and were sold in different years (\texttt{Yr.Sold}).
However, this procedure returned zero matches: no house in the dataset appears to have been sold more than once between 2006 and 2010.
Thus, serial correlation cannot meaningfully arise from repeated observations on the same units.

\begin{lstlisting}[style=rstyle]
# Try to create a new dataset more suitable for DW Test
library(dplyr)
ames_period <- subset(ames_clean, Yr.Sold >= 2006 & Yr.Sold <= 2010)
pid_counts <- ames_period %>%
group_by(PID) %>%
summarise(n_sales = n_distinct(Yr.Sold))

# Identify PIDs with multiple sales
pid_multi <- pid_counts %>%
filter(n_sales >= 2) %>%
pull(PID)

# Create new dataset
ames_multi_sales <- ames_period %>%
filter(PID %in% pid_multi)

# Check for multiple sales
ames_clean %>%
count(PID) %>%
filter(n > 1)

# Alternatively, list the years in which each PID was sold
ames_clean %>%
group_by(PID) %>%
summarise(anni_vendita = paste(unique(Yr.Sold), collapse = ", "),
          n_anni = n_distinct(Yr.Sold)) %>%
filter(n_anni >= 2)

# Final dataset with multiple sales
ames_multi_sales <- ames_clean %>%
group_by(PID) %>%
filter(n_distinct(Yr.Sold) >= 2) %>%
ungroup()
\end{lstlisting}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{scrot_01.png}
    \caption{The dataset contains no repeated sales of the same house.}
    \label{fig:esempio}
\end{figure}

Nevertheless, if we want to compute the \textit{Durbin--Watson statistic} on the model's residuals, it yields a value of approximately 1.84, which is close to the theoretical value of 2 under the null hypothesis of no first--order autocorrelation.
We therefore find no evidence of serial correlation in the residuals, consistent with the cross--sectional nature of the data.

\begin{lstlisting}[style=rstyle]
dwtest(model_transformato_reset)
\end{lstlisting}

\begin{lstlisting}[style=routput]
	Durbin-Watson test

data:  model_transformato_reset
DW = 1.8373, p-value = 0.7604
alternative hypothesis: true autocorrelation is greater than 0
\end{lstlisting}


For completeness, even though we did not make assumptions about the distribution of the residuals, we nevertheless perform the \textit{Jarque--Bera test} for residual normality.
Since the p--value is very low, we reject the null hypothesis and conclude that the residuals are not normally distributed.

\begin{lstlisting}[style=rstyle]
library(tseries)
jarque.bera.test(residuals(model_transformato_reset ))
\end{lstlisting}

\begin{lstlisting}[style=routput]
        Jarque Bera Test

data:  residuals(model_transformato_reset)
X-squared = 9547.3, df = 2, p-value < 2.2e-16
\end{lstlisting}




% ================================
% Model Refinement
% ================================
\section{Model Refinement}

Based on the diagnostic analysis conducted in the previous sections, our original specification does not suffer from perfect or imperfect collinearity, nor does it exhibit structural instability around the 2008 financial crisis. Therefore, no modifications are required to address these two aspects.

The only diagnostic tool that strongly indicates a misspecification is the \textit{RESET test}, which rejects the null hypothesis of linearity for both the original model and its log--transformed version. This suggests that the functional form is not fully adequate and that relevant nonlinearities or interaction effects may be missing.

In the previous section we estimated an extended specification including:
\begin{itemize}
    \item log--transformations of several continuous regressors
    \item interaction terms with clear economic meaning (\(\texttt{GrLivArea} \times \texttt{OverallQual}\))
    \item and an ordered treatment of quality indicators (\texttt{OverallQual}, \texttt{KitchenQual}, \texttt{ExterQual}, \texttt{BsmtQual})
\end{itemize}
and this enriched model passed the \textit{RESET test}, indicating that the specification is now consistent with the maintained assumptions.

For these reasons, we take this transformed and augmented specification as our final model. Its general functional form can be written as:

\[
    \begin{aligned}
        \log(\texttt{[SalePrice]}_i) & =
        \beta_0
        + \beta_1 \,\log(\texttt{[Gr Liv Area]}_i)
        + \beta_2 \,\log(\texttt{[1st Flr SF]}_i) \\
                                     & \quad
        + \beta_3 \,\log(\texttt{[Total Bsmt SF]}_i)
        + \beta_4 \,\log(\texttt{[Lot Area]}_i)
        + \beta_5 \,\texttt{[Full Bath]}_i        \\
                                     & \quad
        + \beta_6 \,\texttt{[Garage Area]}_i
        + \beta_7 \,\texttt{[Garage Cars]}_i
        + \beta_8 \,\texttt{[Year Built]}_i       \\
                                     & \quad
        + \beta_9 \,\texttt{[Year Remod/Add]}_i
        + \beta_{10}\,\texttt{[Overall Qual]}_i
        + \beta_{11}\,\texttt{[Kitchen Qual]}_i   \\
                                     & \quad
        + \beta_{12}\,\texttt{[Exter Qual]}_i
        + \beta_{13}\,\texttt{[Bsmt Qual]}_i
        + \beta_{14}\,\texttt{[Neighborhood]}_i   \\
                                     & \quad
        + \beta_{15}\,\bigl(\texttt{[Gr Liv Area]}_i \times \texttt{[Overall Qual]}_i\bigr)
        + \varepsilon_i .
    \end{aligned}
\]







% ================================
% Conclusions
% ================================
\section{Conclusions}

% This work analysed the determinants of residential property prices in Ames (Iowa) using the \textit{Ames Housing Dataset}, which provides a rich and heterogeneous set of structural, qualitative and locational characteristics for nearly 3{,}000 properties sold between 2006 and 2010. Our objective was to identify which features have a statistically and economically significant impact on sale prices, and to construct a regression model consistent with the assumptions of the classical linear model.

% \subsection*{Summary of empirical findings}

% Our baseline specification (a multiple linear regression including structural size variables, quality measures, and neighbourhood indicators) exhibited a high explanatory power, with an adjusted $R^2$ of about $0.85$. This confirms the central idea underlying hedonic pricing models: the price of real estate can be decomposed into the implicit prices of its attributes. In particular:

% \begin{itemize}
%     \item \textbf{Size and structural attributes} such as \texttt{GrLivArea}, \texttt{TotalBsmtSF}, and \texttt{LotArea} display strong and significant effects on prices. Above--ground living area emerges as one of the strongest continuous predictors.
%     \item \textbf{Quality indicators}, notably \texttt{OverallQual}, \texttt{KitchenQual}, \texttt{ExterQual}, and \texttt{BsmtQual}, play a decisive role. Lower--quality categories consistently carry substantial price discounts relative to top--quality units.
%     \item \textbf{Construction and renovation year} (\texttt{YearBuilt} and \texttt{YearRemodAdd}) contribute positively and significantly, reflecting depreciation effects and the value buyers assign to modernized structures.
%     \item \textbf{Neighbourhood} remains a powerful determinant even in fully specified models, confirming the importance of locational amenities, socio--economic characteristics, and spatial desirability.
% \end{itemize}

% \subsection*{Diagnostic analysis and model adequacy}

% A thorough set of diagnostic tests was conducted to assess the validity of our specification:

% \begin{itemize}
%     \item \textbf{Perfect collinearity} was identified when including all area components (\texttt{GrLivArea}, \texttt{FirstFlrSF}, \texttt{SecondFlrSF}, \texttt{LowQualFinSF}) simultaneously. As expected, \texttt{R} removes one of the collinear variables automatically. The issue disappears when any one of the dependent variables is excluded.
%     \item \textbf{Imperfect collinearity} was evaluated using VIF and GVIF indices. After proper transformation of categorical variables, none of the regressors exhibited problematic values. We therefore ruled out near--collinearity as a major source of estimation distortion.
%     \item \textbf{Structural stability} was tested using the \textit{Chow test} with a breakpoint in 2008, the year associated with the global financial crisis. The test provided no evidence of a structural break: the pricing mechanism appears stable over time, although the intercept shifts downward in post--crisis years. This suggests that the crisis affected the \textit{level} of prices but not the \textit{structure} of price determination.
%     \item \textbf{Heteroskedasticity} was strongly detected via the White test, consistent with expectations for cross--sectional data. HAC robust standard errors can be employed to ensure reliable inference.
%     \item \textbf{Autocorrelation of residuals} was not present, and no repeated sales were found in the dataset to justify a more formal panel--like treatment.
%     \item \textbf{Functional form misspecification} emerged as the most relevant issue: the \textit{RESET test} rejected the null hypothesis for both the baseline linear model and the log--linear variant. This indicates that relevant nonlinearities or omitted interactions were missing in the original specification.
% \end{itemize}

% \subsection*{Final model and economic interpretation}

% Guided by the diagnostic evidence and economic intuition, we refined the model by:

% \begin{itemize}
%     \item applying log--transformations to \texttt{SalePrice} and key continuous regressors
%     \item treating quality variables as \emph{ordered} factors to capture nonlinear differences across quality levels
%     \item introducing an economically meaningful interaction (\texttt{GrLivArea} $\times$ \texttt{OverallQual})
% \end{itemize}

% This enriched specification successfully passed the \textit{RESET test}, indicating a correct functional form.
% Moreover, its structure aligns with widely used formulations in hedonic housing price modelling, particularly semi--log and log--log specifications where coefficients may be interpreted as elasticities.

% \subsection*{Overall Assessment}

% In conclusion, the modelling exercise demonstrates that:

% \begin{itemize}
%     \item house prices in Ames are primarily driven by a combination of structural size, overall and specific quality indicators, and neighbourhood attributes
%     \item nonlinear relationships and interactions are essential to correctly capture the economic mechanisms behind property valuation
%     \item the refined specification provides a flexible, statistically sound and economically interpretable model
%     \item the 2008 financial crisis did not alter the structural relationship between housing attributes and prices, but did affect the absolute level of prices
% \end{itemize}

% The final model therefore offers a robust and insightful representation of the housing market in Ames, and lays the groundwork for potential extensions such as spatial econometric models, non--parametric approaches, or regularized regression methods for high--dimensional settings.



This work analysed the determinants of residential property prices in Ames (Iowa) using the \textit{Ames Housing Dataset}, which provides a rich and heterogeneous set of structural, qualitative and locational characteristics for nearly 3{,}000 residential properties sold between 2006 and 2010. Our objective was to identify which features exert a statistically and economically significant impact on sale prices and to construct a regression model consistent with the assumptions of the classical linear model.

\subsection{Summary of empirical findings}

Our baseline specification (a multiple linear regression including structural size variables, quality measures, and neighbourhood indicators) exhibited a high explanatory power, with an adjusted $R^2$ of approximately $0.85$. The main results can be summarised as follows:

\begin{itemize}
    \item \textbf{Size and structural attributes} such as \texttt{GrLivArea}, \texttt{TotalBsmtSF}, and \texttt{LotArea} display strong and statistically significant effects on housing prices. In particular, above--ground living area emerges as one of the most influential continuous predictors
    \item \textbf{Quality indicators}, including \texttt{OverallQual}, \texttt{KitchenQual}, \texttt{ExterQual}, and \texttt{BsmtQual}, play a decisive role. Lower--quality categories consistently carry substantial price discounts relative to high--quality dwellings
    \item \textbf{Construction and renovation year} (\texttt{YearBuilt} and \texttt{YearRemodAdd}) contribute positively and significantly, reflecting depreciation effects and the price premium associated with more modern or recently renovated properties
    \item \textbf{Neighbourhood effects} remain strong even in a fully specified model, confirming the importance of locational amenities, socio--economic conditions, and spatial desirability in determining sale prices
\end{itemize}

\subsection{Diagnostic analysis and model adequacy}

A comprehensive set of diagnostic tests was performed to assess potential specification issues, as follows.

\paragraph{Perfect collinearity.}
Although perfect collinearity is \emph{not} present in our final model, the Ames dataset contains a known identity that may generate an exact linear dependence if not handled carefully. Including simultaneously \texttt{GrLivArea}, \texttt{FirstFlrSF}, \texttt{SecondFlrSF}, and \texttt{LowQualFinSF} creates perfect multicollinearity, since above--ground living area is mechanically equal to the sum of its components. In such cases OLS computation becomes impossible, and \texttt{R} automatically removes one of the collinear regressors (in our case \texttt{LowQualFinSF}). This highlights the importance of carefully selecting regressors when working with this dataset.

\paragraph{Imperfect collinearity.}
Near multicollinearity was assessed using VIF and GVIF indices. After the appropriate transformation of categorical variables, no regressor exhibited problematic values (i.e.\ VIFs above the common threshold of 10). Therefore, imperfect multicollinearity does not inflate the variance of the estimators, and there is no resulting loss in precision or reliability of inference.

\paragraph{Structural stability.}
Structural stability was evaluated through a \textit{Chow test} with a breakpoint at 2008, the year of the global financial crisis. Despite expectations of instability, the test provides no evidence of a structural break: the pricing mechanism appears stable over time. While this may seem counter--intuitive, a closer look reveals that only the intercept shifts downward in the post--crisis period. This indicates that the crisis affected the general level of house prices but did not change the structure of the relationship between the explanatory variables and the dependent variable. Therefore, our estimated model remains coherent across the entire time span considered.



\bibliographystyle{alpha}
\bibliography{references}
\end{document}
